import logging
import os
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

logger = logging.getLogger(__name__)

def transcriptor(chunks_path):
    """
    Transcribes audio chunks using AI    
    """
    transcripts = []
    logger.info("Loaded Whisper model:{model_size}")

    for path in chunks_path:
        try:
            logger.info(f"Transcribing chunk: {path}")
            with open(path, "rb") as audio_file:
                response = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file
                )
            transcripts.append(response.text)
        except Exception as e:
            logger.error(f"Got an error transcribing {path}: {e}")
    
    full_transcript = "\n".join(transcripts)
    logger.info("âœ… Transcription complete.")
    return full_transcript

def format_transcript(raw_transcript, title):
    """
    Formats raw transcript into well-structured markdown using ChatGPT
    """
    logger.info("ğŸ¨ Formatting transcript with ChatGPT...")
    
    system_prompt = """
You are â€œApuntÃ­nâ€, an academic noteâ€‘taker.

### Hard rules  (the model **must** follow them)

1. **NO INVENTION** â€“ do not add facts, examples or arguments that are absent from the transcript.
2. **Length cap** â€“ output â‰¤â€¯1.2â€¯Ã—â€¯the number of words in the input chunk.  
   *If the transcript has â‰¤â€¯40â€¯words, output a single, concise bullet or direct quote.*
3. Preserve the transcriptâ€™s meaning, but you may:
   â€¢ correct grammar  
   â€¢ remove fillers  
   â€¢ break long sentences.
4. Headings only when the chunk >â€¯80â€¯words.  
   *Otherwise skip headings and keyâ€‘takeaways sections.*
5. When you do use headings:  
   â€¢ H2 for main themes, H3 for subâ€‘themes.  
   â€¢ Bullet points start with â€œ- â€.  
   â€¢ Definitions â†’ `> **Definition**:`, formulas â†’ `$$ â€¦ $$`, code â†’ fenced blocks.
6. Return **pure Markdown** â¯ no YAML frontâ€‘matter, no extra commentary.
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": raw_transcript}
            ],
            max_tokens=4000,
            temperature=0.3
        )
        
        formatted_transcript = response.choices[0].message.content
        logger.info("âœ… Transcript formatting complete.")
        return formatted_transcript
        
    except Exception as e:
        logger.error(f"âŒ Error formatting transcript: {e}")
        logger.info("ğŸ“ Falling back to raw transcript with basic formatting...")
        # Fallback to basic formatting if ChatGPT fails
        return f"# {title}\n\n{raw_transcript}"
